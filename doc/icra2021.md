# ICRA 2021 Submission

This file contains instructions for generating the data and figures shown in our submission. Run all scripts from the root directory of this repository (`/path/to/learned-uncertainty-calibration`).


## Environment Setup
1. Clone the repository:
```
$ git clone https://github.com/stephanietsuei/learned-uncertainty-calibration.git
```
2. Follow instructions [here](setup.md) to setup the proper Python environment.
3. Install the `icra2021` tag of [XIVO](https://github.com/ucla-vision/xivo) and its Python bindings using instructions on [this page](https://github.com/ucla-vision/xivo/blob/icra2021/wiki.md). The Python environment from Step 2 should be active when compiling so that the compiled dynamic libraries are linked to the correct version of Python.


## A Note on Choosing the "Best" Hyperparameters
Several times in the EKF and VIO experiments, we tested many hyperparameters and chose the "best" one. Since our datasets in both experiments consisted of 12 motion sequences, we set aside one sequence as a test set and used the other 11 as a training set. In this process, we were keen to avoid both:
- **overfitting:** choosing hyperparameters that performed well on the training set, but not the test set 
- **randomness:** choosing hyperparameters that performed well on the test set and not the training set

Therefore, we sorted hyperparameters by the sum of their L2 divergences on the overall dataset and test dataset, not just on the test dataset alone. (Overall dataset = training set + test set = all 12 sequences.)



## Linear Kalman Filter Experiment
```
$ python kfexperiments/linear_analysis.py
```


## Extended Kalman Filter Experiment
In this experiment, sequence 11 (the motion sequences are numbered 0-11) is the test sequence. This is hard-coded into all the scripts below.

**1. Generate Monte-Carlo Data for all the Scenarios:**
```
$ python kfexperiments/ekf_analysis.py -mode saveall
```
A new file `ekf_data.pkl` should appear in the root of this repository. It contains data from 50 Monte-Carlo runs for each motion sequence. The first (of 50) run of each motion sequence will become training and/or test data for adjustments below.

**2. Analyze test sequence with unadjusted covariances:**
```
$ python kfexperiments/ekf_loadandplot1.py ekf_data.pkl 'auto'
```

**3. Global Scalar Adjustment:**
```
$ python kfexperiments/ekf_scalar_adjustment.py ekf_data.pkl 'auto'
```

**4. Global Matrix Adjustment:**
The number `2` below is just a random seed, and produced the figures in the submission. The script supports `0`-`10` for that input.
```
$ python kfexperiments/ekf_matrix_adjustment.py ekf_data.pkl compute 2 'auto'
$ python kfexperiments/ekf_matrix_adjustment.py ekf_data.pkl collect 2 'auto'
```

**5. Train Neural Networks:**
We split our training between two GPUs, and gave them IDs 0 and 1. The two commands below were run as two simultaneous jobs.
```
$ python kfexperiments/ekf_train_several.py -gpu_id 0 -data ekf_data.pkl -dnndump [folder of networks]
$ python kfexperiments/ekf_train_several.py -gpu_id 1 -data ekf_data.pkl -dnndump [folder of networks]
```

**6. Inference and Sort Neural Networks:**
Like training, inferencing was also split among two GPUs. The two commands below were run as two simultaneous jobs.
```
$ python kfexperiments/ekf_nn_inference_1run.py -mode compute -data ekf_data.pkl -dnndump [folder of networks] -nbins 'auto' -gpu_id 0
$ python kfexperiments/ekf_nn_inference_1run.py -mode compute -data ekf_data.pkl -dnndump [folder of networks] -nbins 'auto' -gpu_id 1
```

After both jobs are finished, sort the scores to select the best network:
```
$ python kfexperiments/ekf_nn_inference_1run.py -mode collect -data ekf_data.pkl -nbins 'auto'
```

**7. Plot NN-Adjusted Outputs:**
The script in the previous will print the names of the 10 "best" neural networks, sorted by multiple metrics. To plot just one of them on the test set (and generate the figures), run
```
$ python kfexperiments/ekf_nn_predict1.py -data ekf_data.pkl -dnndump [folder of networks] -nbins 'auto' -neural_net [network_name]
```



## VIO Experiment

Although the paper focused on the 9-dimensional orientation + translation + velocity state, the code contains capability to analyze all the following "covariance types":
- **WTV:** orientation/translation/velocity, 9 dimensions
- **W:** Only orientation, 3 dimensions
- **T:** Only translation, 3 dimensions
- **V:** Only velocity, 3 dimensions
- **WT:** orientation/translation, 6 dimensions
Next, for 


Instructions to produce the figures in the paper are below:


**1. Run XIVO on the twelve sequences in the TUM VI Dataset:**
```
$ batch/run_all.sh
```
Output data should appear in the root folder. Move the output data to a folder of your choice. This folder is called `covdump` below.
```
$ mv tumvi_room* covdump
```

**2. Compute sample/ground-truth covariances for each covariance type:** This step is a brute-force grid search over a lot of numbers, so we first compute scores (on the test set and on the entire dataset) for many different window sizes before sorting them:
```
$ python batch/find_sampcov_window.py compute 2000 covdump
```
Sorting:
```
$ python batch/find_sampcov_window.py collect 2000 covdump
```
This prints a list of the best window size for each covariance type and produces plots of divergence against window size. 


**3. Compute and save sample covariances and neural network training data:** (An example of this step is in the file `batch/save_sample_covs.sh`).

First, make a copy of the `covdump` folder for each covariance type:
```
$ cp -r covdump covdump_WTV
$ cp -r covdump covdump_W
$ cp -r covdump covdump_T
$ cp -r covdump covdump_V
$ cp -r covdump covdump_WT
```
Next, save the best window size for each type and sequence in the TUM VI Dataset, for each covariance type (WTV shown below):
```bash
for cam_id in {0..1}
do
  for room_id in {1..6}
  do
    python analysis/eval_cov_calibration.py -mode compute_sample_cov -cam_id ${cam_id} -seq room${room_id} -sample_cov_window_size [WTV window size] -dump covdump_WTV
  done
done
```
Finally, get the formatted data for all three neural network inputs (cov, gsbcov, gsbvcov) and save:
```
$ python analysis/dense_layers_adjustment.py -dump covdump_WTV -process_text -cov_type WTV -input_mode cov
$ python analysis/dense_layers_adjustment.py -dump covdump_WTV -process_text -cov_type WTV -input_mode gsbcov
$ python analysis/dense_layers_adjustment.py -dump covdump_WTV -process_text -cov_type WTV -input_mode gsbvcov
```

**4. Compute global scalar adjustment:**
For each covariance type (WTV shown below), run:
```
$ python analysis/single_scalar_adjustment.py -cov_type WTV -dump covdump_WTV
$ python analysis/single_scalar_adjustment.py -cov_type W -dump covdump_W
$ python analysis/single_scalar_adjustment.py -cov_type T -dump covdump_T
$ python analysis/single_scalar_adjustment.py -cov_type V -dump covdump_V
$ python analysis/single_scalar_adjustment.py -cov_type WT -dump covdump_WT
```
Each command above is one QP, so this should be quick. The script will automatically save the scalars to the output files stored in each `covdump_[covariance type]` directory.

   
**5. Compute global matrix adjustment:**
Because nonlinear optimization is slow, we ran the five commands below as five simultaneous jobs:
```
$ python analysis/single_matrix_adjustment.py -estimate_jac -cov_type WTV -dump covdump_WTV
$ python analysis/single_matrix_adjustment.py -estimate_jac -cov_type W -dump covdump_W
$ python analysis/single_matrix_adjustment.py -estimate_jac -cov_type T -dump covdump_T
$ python analysis/single_matrix_adjustment.py -estimate_jac -cov_type V -dump covdump_V
$ python analysis/single_matrix_adjustment.py -estimate_jac -cov_type WT -dump covdump_WT
```
As in the global scalar adjustment script in above, each command will save the matrices to the output files stored in each `covdump_[covariance_type]` directory.


**6. Train neural networks:**
Like in the EKF experiment, this was split into two jobs running simultaneously for each covariance type. Each job took one GPU. (GPU 0 is significantly more powerful than GPU 1, thus we make it train larger networks, as indicated in `batch/train_several.py`.) Output neural networks are saved to a directory that will be called `dnndump_[covariance type]` below.

The command for WTV covariance type is:
```
$ python batch/train_several.py -dump covdump_WTV -dnndump dnndump_WTV -cov_type WTV -gpu_id 0
$ python batch/train_several.py -dump covdump_WTV -dnndump dnndump_WTV -cov_type WTV -gpu_id 1
```
An example (for each GPU) is automated in the script `batch/train_all.sh`.


**7. Inference neural networks:**
Neural network inferencing is also split between two GPUs. Run this command (for each covariance type; the command for WTV is shown below) for each covariance type AFTER all training has finished:
```
$ python batch/process_dense_networks.py -mode compute -dump covdump_WTV -dnndump dnndump_WTV -cov_type WTV -nbins 2000
```
Afterwards, collect the inferencing results and find the best trained network:
```
$ python batch/process_dense_networks.py -mode collect -dump covdump_WTV -dnndump dnndump_WTV -cov_type WTV -nbins 2000
```

**8. Compute calibrations of adjustments:**
For a single sequence (e.g. the test sequence), use the following command for a particular sequence (room1-room6) and camera id (0 or 1) with an adjustment that is not a neural net:
```
$ python analysis/eval_cov_calibration.py -seq [room1-6] -cam_id [0 or 1] -cov_type [covariance type | all ] -dump covdump_[covariance_type] -cov_source [ original | sampled | scalar | linear ]
```
For a single sequence with a neural net the command is:
```
$ python analysis/eval_cov_calibration.py -seq [room1-6] -cam_id [0 or 1] -cov_type [covariance type] -dump covdump_[covariance_type] -cov_source neural_net -network_dump dnndump_[covariance type] -network_model [network_name]
```
To evaluate over the entire dataset (training and test), with an adjustment that is not a neural net the command is:
```
$ python analysis/eval_overall_calibration.py -dump covdump_[covariance_type] -cov_source [original | sampled | scalar | linear ] -cov_type [covariance_type | all]
```

With a neural net, the command is:
```
$ python analysis/eval_overall_calibration.py -dump covdump_[covariance_type] -cov_source neural_net -cov_type [covariance_type | all ] -network_dump dnndump_[covariance type] -network_model [network_name]
```
